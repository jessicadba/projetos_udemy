{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuração e conexão entre Python e o Google BigQuery\n",
    "O Python pode se conectar ao Google BigQuery usando diferentes métodos de autenticação, dependendo do ambiente e das permissões necessárias. Irei apresentar aqui as principais formas apresentadas durante o curso: **Autenticação com Service Account (Conta de Serviço)** e **Application Default Credentials (ADC)**.\n",
    "\n",
    "#### Autenticação com Service Account (Conta de Serviço)\n",
    "Durante o curso, realizei a configuração das credenciais dentro do Google Cloud Console, que gerencia as configurações de autenticação para BigQuery e outras APIs do Google Cloud, seguindo os seguintes passos:\n",
    "\n",
    "**Exemplo de configuração:**\n",
    "\n",
    "- Acessar a aba APIs e serviços -> Credenciais -> Criar Credenciais -> Conta de serviço (Passar os parâmetros do projeto como: Nome e ID da Conta de Serviço)\n",
    "\n",
    "- Gerenciar permissões: Atribua o papel de *Propietário*, *BigQuery Admin* e *Agente do BigQuery Data Transfer Service*, dependendo do nível de acesso desejado.\n",
    "\n",
    "- Após essas configurações, a chave de autenticação será armazenada localmente em um arquivo *.json*.\n",
    "\n",
    "![teste](credenciais_gbq.jpg)\n",
    "\n",
    "#### Application Default Credentials (ADC)\n",
    "As credenciais padrão do Google Cloud (Application Default Credentials - ADC) no ambiente local, permitem que aplicações interajam com APIs do Google Cloud sem precisar de um arquivo JSON de chave de serviço. Elas são úteis para desenvolvimento e testes sem configuração manual de autenticação.\n",
    "\n",
    "**Como funcionam?**\n",
    "- São armazenadas automaticamente no computador local após autenticação.\n",
    "\n",
    "- Permitem acesso a APIs do Google Cloud sem precisar especificar credenciais dentro do código.\n",
    "\n",
    "- Usam o login da conta Google para gerar um token de autenticação.\n",
    "\n",
    "**Exemplo de configuração:**\n",
    "\n",
    "Para configurar credenciais padrão no ambiente local, é necessário executar o seguinte comando no terminal:\n",
    "\n",
    "``` bash\n",
    "# Comando\n",
    "gcloud auth application-default login\n",
    "```\n",
    "Isso abrirá uma página no navegador para login na conta do Google. Após a autenticação, as credenciais serão armazenadas e usadas automaticamente quando o Python acessar APIs do Google Cloud.\n",
    "\n",
    "### Projeto Prático\n",
    "As linhas de código apresentadas abaixo, permitem configurar a conexão entre o Python e o Google BigQuery de forma segura, permitindo a manipulação de dados dentro do BigQuery diretamente pelo código Python. Irei explicar o passo a passo dessa configuração a seguir!\n",
    "\n",
    "#### Instalação das bibliotecas - Entendendo os comandos que serão utilizados:\n",
    "Para acessar, consultar, manipular e enviar dados para o BigQuery diretamente pelo código, é essencial instalar algumas bibliotecas.\n",
    "\n",
    "- **pip install google-cloud-bigquery:**\n",
    "Instala o cliente da biblioteca *google-cloud-bigquery*, que permite interagir com o Google BigQuery através do Python.\n",
    "\n",
    "- **pip install --upgrade google-cloud-bigquery:**\n",
    "Atualiza o pacote *google-cloud-bigquery* para a versão mais recente disponível.\n",
    "\n",
    "- **pip install pandas:** \n",
    "Instala o Pandas, uma biblioteca essencial para manipulação e análise de dados em Python.\n",
    "\n",
    "- **pip install pandas pandas-gbq:** \n",
    "Instala ambos os pacotes pandas e pandas-gbq. O *pandas-gbq* é um complemento do Pandas que facilita a integração com o Google BigQuery.\n",
    "\n",
    "``` python\n",
    "# Comandos executados no terminal\n",
    "pip install google-cloud-bigquery\n",
    "pip install --upgrade google-cloud-bigquery\n",
    "pip install pandas\n",
    "pip install pandas pandas-gbq\n",
    "```\n",
    "\n",
    "- **import pandas as pd:** Importa o Pandas para realizar a manipulação e análise de dados no Python.\n",
    "\n",
    "- **from google.cloud import bigquery:** Importa o cliente do Google BigQuery, permitindo a interação com o banco de dados.\n",
    "\n",
    "- **from google.oauth2 import service_account:** Importa o módulo para autenticação via Service Account, que é uma forma segura de acessar o Google BigQuery.\n",
    "\n",
    "- **from pandas_gbq import to_gbq:** Importa a função to_gbq, usada para enviar DataFrames do Pandas diretamente para o BigQuery.\n",
    "\n",
    "``` python\n",
    "# Importar as bibliotecas no código\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from pandas_gbq import to_gbq\n",
    "\n",
    "# Carregar as credenciais do arquivo JSON contendo a chave da Service Account. O argumento scopes define quais permissões serão concedidas, no caso, acesso ao BigQuery.\n",
    "credencial = service_account.Credentials.from_service_account_file(\n",
    "    r'C:\\caminho\\arquivo\\pythoncurso-123456-0i0000000f0b.json' # exemplo\n",
    "    scopes=['https://www.googleapis.com/auth/bigquery']\n",
    ")\n",
    "```\n",
    "Após a execução desse código o ambiente estará pronto para consultar e enviar informações ao BigQuery, onde será possível realizar consultas SQL, enviar DataFrames do Pandas para BigQuery e interagir com os dados na nuvem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste de conexão 1: Utilizando: *from google.cloud import bigquery*\n",
    "O comando **from google.cloud import bigquery** em Python é usado para importar o cliente BigQuery do Google Cloud. Com essa importação, podemos interagir com bancos de dados do BigQuery diretamente pelo Python. Isso inclui a execução de consultas, manipulação de tabelas e conjuntos de dados, além da integração com outras ferramentas de análise.\n",
    "\n",
    "**Exemplo:** O código abaixo realiza uma consulta SQL no Google BigQuery usando Python e armazena os resultados em um DataFrame do Pandas. Vamos entender cada parte:\n",
    "\n",
    "``` python\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Armazena o caminho do arquivo JSON que contêm as credenciais de autenticação para o Google BigQuery\n",
    "credencial = r\"C:\\caminho\\arquivo\\pythoncurso-123456-0i0000000f0b.json\" # exemplo\n",
    "\n",
    "# Cria um cliente do BigQuery autenticado com as credenciais da Service Account, permitindo acessar e manipular dados no BigQuery\n",
    "client = bigquery.Client.from_service_account_json(credencial)\n",
    "\n",
    "# Aqui, estamos definindo uma consulta SQL que seleciona todos os registros (SELECT *) da tabela TB_CLIENTE, localizada dentro do dataset Aula_Python no projeto pythoncurso-123456.\n",
    "query = \"\"\"\n",
    "\n",
    "  SELECT * FROM `pythoncurso-123456.Aula_Python.TB_CLIENTE` \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# O client bigquery executa a consulta e retorna os dados. Os resultados ficam armazenados na variável resultado, que é um objeto de consulta, ainda não transformado em um DataFrame.\n",
    "resultado = client.query(query)\n",
    "\n",
    "# Aqui, convertemos os dados da consulta para um DataFrame do Pandas, permitindo manipulação e análise dos dados no Python. Agora podemos usar funções do Pandas como df.head() para visualizar os primeiros registros ou df.describe() para estatísticas dos dados.\n",
    "df = resultado.to_dataframe()\n",
    "df.head(5)\n",
    "\n",
    "```\n",
    "![dataframe.jpg](dataframe.jpg)\n",
    "\n",
    "Importar uma tabela do Google BigQuery e armazená-la em um DataFrame do Pandas é uma maneira eficiente de acessar, manipular e analisar dados diretamente no Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Teste de conexão 2: Utilizando: *from google.oauth2 import service_account*\n",
    "O comando **from google.oauth2 import service_account** em Python é usado para importar a funcionalidade de autenticação baseada em contas de serviço do Google. Isso permite a conexão de forma segura aos serviços do Google Cloud sem precisar de autenticação manual toda vez. Com essa importação, podemos criar credenciais e usá-las para autenticar e autorizar as solicitações automaticamente.\n",
    "\n",
    "**Exemplo:**\n",
    "```python\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "\n",
    "# Especifique as informaçoes de credenciais que estão contidas dentro do arquivo JSON (Abra o arquivo e copie e cole as informações aqui). OBS: Essas informções são confidencias. No exemplo anterior, passamos o caminho onde o arquivo JSON está salvo. Agora iremos informar o conteúdo do arquivo.\n",
    "\n",
    "credencial = {\n",
    "  \"type\": \"service_account\",\n",
    "  \"project_id\": \"pythoncurso-123456\",\n",
    "  \"private_key_id\": \"00000000000000000ei000000ee000000\",\n",
    "  \"private_key\": \"demais informações**********\",\n",
    "  \"client_email\": \"aulapythoncurso@pythoncurso-123456.iam.gserviceaccount.com\",\n",
    "  \"client_id\": \"1234567890123456789\",\n",
    "  \"auth_uri\": \"https://accounts.google.com/o/oauth2/auth\",\n",
    "  \"token_uri\": \"https://oauth2.googleapis.com/token\",\n",
    "  \"auth_provider_x509_cert_url\": \"https://www.googleapis.com/oauth2/v1/certs\",\n",
    "  \"client_x509_cert_url\": \"https://www.googleapis.com/robot/v1/metadata/x509/aulapythoncurso%40pythoncurso-123456.iam.gserviceaccount.com\",\n",
    "  \"universe_domain\": \"googleapis.com\"\n",
    "}\n",
    "\n",
    "# Cria um cliente do BigQuery usando credenciais de uma conta de serviço\n",
    "client = bigquery.Client(credentials=service_account.Credentials.from_service_account_info(credencial))\n",
    "\n",
    "# Construa sua consulta\n",
    "query = \"\"\" \n",
    "\n",
    "  SELECT \n",
    "  id\n",
    "  ,first_name\n",
    "  ,last_name\n",
    "  ,email  \n",
    "  ,state\n",
    " FROM `pythoncurso-123456.Aula_Python.TB_CLIENTE` \n",
    " where state in ('Piauí','Alagoas','Amazonas','Maranhão','Rondônia')\n",
    "\n",
    "\"\"\"\n",
    "# Execute a consulta\n",
    "resultado = client.query(query)\n",
    "\n",
    "# Converta os resultados em um DataFrame\n",
    "df = resultado.to_dataframe()\n",
    "df.head(30)\n",
    "\n",
    "```\n",
    "![dataframe2](dataframe2.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Carregando dados para o Google BigQuery utilizando *from pandas_gbq import to_gbq*\n",
    "Com essa função, podemos salvar um DataFrame diretamente em uma tabela do BigQuery sem precisar escrever SQL manualmente.\n",
    "\n",
    "**Exemplo 1:**\n",
    "```python\n",
    "import pandas as pd\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "from pandas_gbq import to_gbq\n",
    "\n",
    "# Carregue suas credenciais\n",
    "credencial = service_account.Credentials.from_service_account_file(\n",
    "    r'C:\\caminho\\arquivo\\pythoncurso-123456-0i0000000f0b.json',\n",
    "    scopes=['https://www.googleapis.com/auth/bigquery']\n",
    ")\n",
    "\n",
    "# Ler o arquivo com os dados e carrega em um dataframe\n",
    "df = pd.read_excel(r\"C:\\caminho_do_arquivo\\exemplo_excel\\Produto.xlsx\")\n",
    "df.head()\n",
    "\n",
    "# Envie o DataFrame para o BigQuery inserindo o caminho onde os dados serão carregados em uma tabela\n",
    "df.to_gbq(destination_table='pythoncurso-123456.Aula_Python.TB_PRODUTO',  # caminho da tabela onde os dados serão carregados\n",
    "          project_id='pythoncurso-123456',\n",
    "          if_exists='replace', # se a tabela já existir irá subistuir pela nova que está sendo carregada\n",
    "          credentials=credencial)\n",
    "\n",
    "# if_exists='replace' = subistui a antiga pela atual \n",
    "# if_exists='append' = adiciona dados no fim da tabela\n",
    "\n",
    "```\n",
    "**Exemplo 2:**\n",
    "```python\n",
    "# Carregue suas credenciais\n",
    "credencial = service_account.Credentials.from_service_account_file(\n",
    "    r'C:\\caminho\\arquivo\\pythoncurso-123456-0i0000000f0b.json',\n",
    "    scopes=['https://www.googleapis.com/auth/bigquery']\n",
    ")\n",
    "\n",
    "# Insira os parâmetros do seu projeto no Google BigQuery dentro de variáves (Boa prática quando temos que subir mais de um conjuto de dados (dataframes) em um mesmo dataset)\n",
    "projeto = 'pythoncurso-123456'\n",
    "dataset = 'Aula_Python'\n",
    "tabela = 'Produto_2'\n",
    "parametro = 'append'\n",
    "\n",
    "# Aqui passamos as variáveis com os parâmetos que carregamos acima\n",
    "df.to_gbq(destination_table=f'{projeto}.{dataset}.{tabela}',\n",
    "          project_id=projeto,\n",
    "          if_exists=parametro,\n",
    "          credentials=credencial)\n",
    "\n",
    "```\n",
    "**Exemplo 3:**\n",
    "```python\n",
    "# Carregando vários arquivos de um projeto (mapeamento da origem dos dados)\n",
    "produto     = pd.read_excel(r\"C:\\Arquivos\\Origem\\arquivos_excel\\Produto.xlsx\")\n",
    "itens       = pd.read_excel(r\"C:\\Arquivos\\Origem\\arquivos_excel\\items.xlsx\")\n",
    "ordens      = pd.read_excel(r\"C:\\Arquivos\\Origem\\arquivos_excel\\Ordens.xlsx\")\n",
    "categoria   = pd.read_excel(r\"C:\\Arquivos\\Origem\\arquivos_excel\\Categoria.xlsx\")\n",
    "cliente     = pd.read_csv(r\"C:\\Arquivos\\Origem\\arquivos_csv\\Clientes.csv\", delimiter=',')\n",
    "\n",
    "# Insira os parâmetros do seu projeto no Google BigQuery e as variáves que irão receber o nome das tabelas onde os dados serão armazenados dentro do BigQuery\n",
    "projeto         = 'pythoncurso-123456'\n",
    "dataset         = 'Ecommerce'\n",
    "bq_produto      = 'TB_PRODUTO'\n",
    "bq_itens        = 'TB_ITENS'\n",
    "bq_ordens       = 'TB_ORDENS'\n",
    "bq_categoria    = 'TB_CATEGORIA'\n",
    "bq_cliente      = 'TB_CLIENTE'\n",
    "parametro       = 'replace'\n",
    "\n",
    "# Carregue suas credenciais para importar os dados para o BigQuery\n",
    "credencial = service_account.Credentials.from_service_account_file(\n",
    "    r'C:\\caminho\\arquivo\\pythoncurso-123456-0i0000000f0b.json',\n",
    "    scopes=['https://www.googleapis.com/auth/bigquery']\n",
    ")\n",
    "\n",
    "# Agora para cada conjunto de dados iremos inserir o caminho onde os dados serão carregados\n",
    "produto.to_gbq(destination_table=f'{projeto}.{dataset}.{bq_produto}',\n",
    "          project_id=projeto,\n",
    "          if_exists=parametro,\n",
    "          credentials=credencial)\n",
    "\n",
    "itens.to_gbq(destination_table=f'{projeto}.{dataset}.{bq_itens}',\n",
    "          project_id=projeto,\n",
    "          if_exists=parametro,\n",
    "          credentials=credencial)\n",
    "\n",
    "ordens.to_gbq(destination_table=f'{projeto}.{dataset}.{bq_ordens}',\n",
    "          project_id=projeto,\n",
    "          if_exists=parametro,\n",
    "          credentials=credencial)\n",
    "\n",
    "categoria.to_gbq(destination_table=f'{projeto}.{dataset}.{bq_categoria}',\n",
    "          project_id=projeto,\n",
    "          if_exists=parametro,\n",
    "          credentials=credencial)\n",
    "\n",
    "cliente.to_gbq(destination_table=f'{projeto}.{dataset}.{bq_cliente}',\n",
    "          project_id=projeto,\n",
    "          if_exists=parametro,\n",
    "          credentials=credencial)\n",
    "```\n",
    "\n",
    "**Resultado Carga Google BigQuery:**\n",
    "\n",
    "\n",
    "![carga_gbq](carga_gbq.jpg)\n",
    "\n",
    "\n",
    "### Extração de dados do Google BigQuery\n",
    "\n",
    "```python\n",
    "# Importação das bibcliotecas para extrair e manipular os dados do BigQuery com Python\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "\n",
    "# Carregue suas credenciais que permitirá realizar consultas aos dados no BigQuery\n",
    "credencial = r\"C:\\Users\\casnav\\workspace\\Udemy\\pythoncurso-123456-0e0000000f0b.json\"\n",
    "client = bigquery.Client.from_service_account_json(credencial)\n",
    "\n",
    "# Desenvolvimento das consultas no Google BigQuery\n",
    "consulta_produto = \"\"\"\n",
    "SELECT * FROM `pythoncurso-455516.Ecommerce.TB_PRODUTO` limit 30\n",
    "\"\"\"\n",
    "\n",
    "consulta_categoria = \"\"\"\n",
    "SELECT * FROM `pythoncurso-455516.Ecommerce.TB_CATEGORIA` limit 30\n",
    "\"\"\"\n",
    "\n",
    "consulta_cliente = \"\"\"\n",
    "SELECT * FROM `pythoncurso-455516.Ecommerce.TB_CLIENTE` limit 30\n",
    "\"\"\"\n",
    "\n",
    "consulta_itens = \"\"\"\n",
    "SELECT * FROM `pythoncurso-455516.Ecommerce.TB_ITENS` LIMIT 30\n",
    "\"\"\"\n",
    "\n",
    "consulta_ordens = \"\"\"\n",
    "SELECT * FROM `pythoncurso-455516.Ecommerce.TB_ORDENS` LIMIT 30\n",
    "\"\"\"\n",
    "\n",
    "# Executa e traz o resultado das consultas realizadas acima\n",
    "resultado_consulta_prod = client.query(consulta_produto)\n",
    "resultado_consulta_catg = client.query(consulta_categoria)\n",
    "resultado_consulta_clit = client.query(consulta_cliente)\n",
    "resultado_consulta_ites = client.query(consulta_itens)\n",
    "resultado_consulta_ords = client.query(consulta_ordens)\n",
    "\n",
    "# Converte os resultados das consultas e armazena em um Dataframe\n",
    "df_produto      = resultado_consulta_prod.to_dataframe()\n",
    "df_categoria    = resultado_consulta_catg.to_dataframe()\n",
    "df_cliente      = resultado_consulta_clit.to_dataframe()\n",
    "df_itens        = resultado_consulta_ites.to_dataframe()\n",
    "df_ordens       = resultado_consulta_ords.to_dataframe()\n",
    "\n",
    "# Tratamento de datas no dataframe Ordens\n",
    "df_ordens['created_at'] = df_ordens['created_at'].dt.tz_localize(None)\n",
    "df_ordens.head()\n",
    "\n",
    "# Passar os parâmetros de destino onde os dados extraídos serão armazenados\n",
    "pasta = r\"C:\\caminho\\aulas\\Udemy\\extracao\\\\\" # Todos os arquivos serão armazenados em uma única pasta\n",
    "nomearquivoproduto      = \"ext_produto.xlsx\"\n",
    "nomearquivocategoria    = \"ext_categoria.xlsx\"\n",
    "nomearquivocliente      = \"ext_cliente.xlsx\"\n",
    "nomearquivoitens        = \"ext_itens.xlsx\"\n",
    "nomearquivoordens       = \"ext_ordens.xlsx\"\n",
    "\n",
    "# Armazenamento dos dataframes no excel\n",
    "df_produto.to_excel(pasta+nomearquivoproduto, index=False)\n",
    "df_categoria.to_excel(pasta+nomearquivocategoria, index=False)\n",
    "df_cliente.to_excel(pasta+nomearquivocliente, index=False)\n",
    "df_itens.to_excel(pasta+nomearquivoitens, index=False)\n",
    "df_ordens.to_excel(pasta+nomearquivoordens, index=False)\n",
    "```\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
